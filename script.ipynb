{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"script.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"QdueYHS2k_1A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"427b8065-9fe6-4ea5-f24c-2e4e0b9549ab","executionInfo":{"status":"ok","timestamp":1588109251377,"user_tz":300,"elapsed":1643,"user":{"displayName":"Harish S Bommakanti","photoUrl":"","userId":"06093719475374632656"}}},"source":["#set up google colab stuff\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","#!ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pklNH-GXjux-","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from keras import Sequential\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dense, Dropout, GlobalMaxPooling1D, Conv1D, MaxPooling1D, Embedding\n","from keras.layers.normalization import BatchNormalization\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ekro4wS8juyC","colab_type":"code","colab":{}},"source":["# prepare training data array consisting of meme id's, binary identification of top caption v bottom caption, and the characters in each caption\n","colab_filepath_addon = \"/content/drive/My Drive/Colab/Deep-Fried-Learning/\"\n","raw_data = pd.read_csv(colab_filepath_addon +  \"Meme_training_data.csv\")\n","#confirm that the csv was read correctly\n","#print(raw_data.head())\n","\n","training_data = []\n","character_to_int_mapping = []\n","\n","#populate the training_data array\n","def process_string(string,memeid,topOrBottom):\n","    #append numbers of the memeid to the character_int mapping array\n","    if memeid not in character_to_int_mapping:\n","        character_to_int_mapping.append(str(memeid))\n","    memeid = str(memeid).zfill(4) #pad the memeid with zeroes before hand to make all id's the same length\n","    \n","    #if the dataframe held a NaN float value there (intentionally), it was a blank caption\n","    if (isinstance(string,float)):\n","        #then, there is only 1 element, with the characters_seen being blank and the next_character being |\n","        new_entry_first_string = (\"%s %d %s\" %(memeid,topOrBottom,\" \"))\n","        next_character = \"|\"\n","\n","        training_data.append([new_entry_first_string,next_character])\n","\n","    else: #go ahead as planned\n","\n","        characters_seen = \"\"\n","        for j in range(len(string)+1):\n","            #i is the memeid, topOrBottom says 0 if its a top caption, 1 if its a bottom caption\n","            new_entry_first_string = (\"%s %d %s\" %(memeid,topOrBottom,characters_seen))\n","            \n","            #if the new character is a space, or if the string ended, add |\n","            next_character = \"\"\n","            if j == len(string) or string[j]==\" \":\n","                next_character = \"|\"\n","            else:\n","                next_character = string[j]\n","\n","            #append to the character to int mapping array\n","            if not(next_character in character_to_int_mapping):\n","                character_to_int_mapping.append(next_character)\n","            #append both strings to a new array, and add that array to training_data\n","            training_data.append([new_entry_first_string,next_character])\n","\n","            characters_seen += next_character\n","\n","#for each image\n","for i in range(len(raw_data)):\n","    top_caption = raw_data[\"Top Caption\"][i]\n","    bottom_caption = raw_data[\"Bottom Caption\"][i]\n","\n","    #for each character in the either caption, the format is the following:\n","    # [\"{memeID}   {binaryClassifierForToporBottom}  {characters including up to and including that character}\",\"{the next character}\"]\n","    # notice that the entry has 2 strings\n","\n","    #passing in the string, i==memeid, and the binary classifier for top or bottom string, for both the top and the bottom captions\n","    process_string(top_caption,i,0)\n","    process_string(bottom_caption,i,1)\n","\n","\n","#check if populating array was ok\n","def check_training_data_arr():\n","    test_file = open(\"check_training_data_arr.txt\",\"w\")\n","    for i in training_data:\n","        print(i,\"\\n\",file = test_file)\n","\n","#check_training_data_arr()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbtPO77FjuyK","colab_type":"code","colab":{}},"source":["# tensorize the data, reshape to fit into the CNN\n","main_texts = [i[0] for i in training_data]\n","labels = [i[1] for i in training_data]\n","\n","character_to_int_mapping.append(\" \") #spaces weren't ever accounted for when populating training_data array\n","#print(character_to_int_mapping)\n","\n","#reshape the texts and lables array to be indices of the character_to_int_mapping array\n","\n","#transform the main texts\n","transformed_main_texts = []\n","for row in main_texts:\n","    transformed_row = []\n","    for char in row:\n","        transformed_row.append(character_to_int_mapping.index(char))\n","    transformed_main_texts.append(transformed_row)\n","\n","#transform the labels\n","transformed_labels = []\n","for entry in labels: #entry will just be a 1 character string, its the 'next character'\n","    transformed_labels.append(character_to_int_mapping.index(entry))\n","\n","#testing\n","#print(transformed_main_texts[0:70])\n","#print(transformed_labels)\n","\n","#pad the main texts with 0's so they're the same length using keras.tf pad_sequences\n","padding_length = 128\n","main_data = pad_sequences(transformed_main_texts,maxlen=padding_length)\n","\n","#print(main_data)[0:70]\n","\n","#randomize training data (stats :pog:)\n","indices = np.arange(main_data.shape[0]) #gets array of indices from len(main_data)\n","np.random.shuffle(indices) #shuffles indices\n","main_data = main_data[indices] #assigns a new order for the array\n","for i in range(len(indices)):\n","    transformed_labels[i] = transformed_labels[indices[i]]\n","\n","#ratios help the model cross reference it's predictions to memes its not referencing in the training set\n","ratio = .2 if main_data.shape[0] < 1000000 else .02\n","num_val_samples = int(ratio * main_data.shape[0])\n","\n","#split the data based on the ratios\n","x_train = main_data[:-num_val_samples] #the first to the last {num_val_samples}'th samples\n","y_train = transformed_labels[:-num_val_samples] \n","x_test = main_data[-num_val_samples:] #the {num_val_samples}'th sample to the end\n","y_test = transformed_labels[-num_val_samples:]\n","\n","#testing\n","#print(x_train)\n","#print(x_test)\n","#print(y_train)\n","#print(y_test)\n","\n","#end preprocessing\n","#-------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKMOCi7kjuyS","colab_type":"code","colab":{}},"source":["#model creation\n","\n","#CNN model\n","EMBEDDING_DIM = 16\n","\n","CNNmodel = Sequential()\n","CNNmodel.add(Embedding(len(character_to_int_mapping) + 1, EMBEDDING_DIM, input_length=padding_length)) #Embedding layer to convert the 128 char long array to 128x16 matrix: helps convert to integers instead of floats\n","CNNmodel.add(Conv1D(1024, 5, activation='relu', padding='same'))                                       #Conv1D layers with 1024 output filters, kernel size of 5 (length of convolution filter): looks at constructing words from chars\n","CNNmodel.add(BatchNormalization())                                                                     #BatchNormalization so that the next layers are normalized based on the mean/variance for current layer, helps improving training speed\n","CNNmodel.add(MaxPooling1D(2))                                                                          #Pooling reduces spatial size of features (by 2 in this case) to help computation in the network\n","CNNmodel.add(Dropout(0.25))                                                                            #Drops out a random 25% of data to avoid overfit\n","CNNmodel.add(Conv1D(1024, 5, activation='relu', padding='same'))                                       #relu activation is basically max(0,input), is good for a function that accepts the weighted values and outputs a direct value to an output node\n","CNNmodel.add(BatchNormalization())                                                                     #same padding ensures that the dimensions of the output layer match the dimensions of the input layer\n","CNNmodel.add(MaxPooling1D(2))\n","CNNmodel.add(Dropout(0.25))\n","CNNmodel.add(Conv1D(1024, 5, activation='relu', padding='same'))\n","CNNmodel.add(BatchNormalization())\n","CNNmodel.add(MaxPooling1D(2))\n","CNNmodel.add(Dropout(0.25))\n","CNNmodel.add(Conv1D(1024, 5, activation='relu', padding='same'))\n","CNNmodel.add(BatchNormalization())\n","CNNmodel.add(MaxPooling1D(2))\n","CNNmodel.add(Dropout(0.25))\n","CNNmodel.add(Conv1D(1024, 5, activation='relu', padding='same'))\n","CNNmodel.add(BatchNormalization())\n","CNNmodel.add(GlobalMaxPooling1D())                                                                     #GlobalMaxPooling1D also shrinks layer, but automatically chooses how to do it (instead of the param of 2 in previous calls)\n","CNNmodel.add(Dropout(0.25))\n","CNNmodel.add(Dense(1024, activation='relu'))\n","CNNmodel.add(BatchNormalization())\n","CNNmodel.add(Dropout(0.25))\n","CNNmodel.add(Dense(len(transformed_labels), activation='softmax'))                                           #Dense houses the activation function, specifies the softmax activation function (nonlinear)\n","\n","CNNmodel.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])         #compile the CNNmodel: rmsprop optimizer is good optimizer, the loss is specific to our example when we optimize for choosing the best category among 2 labels (top/bottom captions). sparse because the labels are ints between 0 and 70 (good for memory)\n","#CNNmodel.summary()\n","\n","\n","#should come back to add a GAN model for cross comparison after we get the CNN model up and running\n","#end model-creation(?)\n","#----------------------------------------------------------"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"42sm9Yp1juyb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"954d87a2-ef3c-4393-8db9-0f69f90f983e","executionInfo":{"status":"ok","timestamp":1588109362962,"user_tz":300,"elapsed":113138,"user":{"displayName":"Harish S Bommakanti","photoUrl":"","userId":"06093719475374632656"}}},"source":["#Training time\n","model_path = \"models/conv_model\"\n","num_epochs = 48\n","batch_size = 256\n","\n","checkpointer = ModelCheckpoint(filepath = colab_filepath_addon + model_path + '/model.h5',verbose=1,save_best_only=True)\n","\n","#print(len(x_train[0]),len(y_train),len(x_test),len(y_test))\n","history = CNNmodel.fit(x_train,y_train, validation_data=(x_test,y_test),epochs=num_epochs,batch_size=batch_size,callbacks=[checkpointer])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 1688 samples, validate on 422 samples\n","Epoch 1/48\n","1688/1688 [==============================] - 3s 2ms/step - loss: 7.8756 - acc: 0.0373 - val_loss: 7.7127 - val_acc: 0.0000e+00\n","\n","Epoch 00001: val_loss improved from inf to 7.71274, saving model to /content/drive/My Drive/Colab/Deep-Fried-Learning/models/conv_model/model.h5\n","Epoch 2/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 7.4416 - acc: 0.0995 - val_loss: 8.1349 - val_acc: 0.0000e+00\n","\n","Epoch 00002: val_loss did not improve from 7.71274\n","Epoch 3/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 7.1195 - acc: 0.0906 - val_loss: 8.7112 - val_acc: 0.0450\n","\n","Epoch 00003: val_loss did not improve from 7.71274\n","Epoch 4/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 6.7549 - acc: 0.0966 - val_loss: 9.6947 - val_acc: 0.0000e+00\n","\n","Epoch 00004: val_loss did not improve from 7.71274\n","Epoch 5/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 6.3237 - acc: 0.1055 - val_loss: 10.4595 - val_acc: 0.0213\n","\n","Epoch 00005: val_loss did not improve from 7.71274\n","Epoch 6/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 5.8538 - acc: 0.1102 - val_loss: 11.3090 - val_acc: 0.0000e+00\n","\n","Epoch 00006: val_loss did not improve from 7.71274\n","Epoch 7/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 5.2071 - acc: 0.1137 - val_loss: 11.7321 - val_acc: 0.0000e+00\n","\n","Epoch 00007: val_loss did not improve from 7.71274\n","Epoch 8/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 4.7355 - acc: 0.1351 - val_loss: 11.0364 - val_acc: 0.0450\n","\n","Epoch 00008: val_loss did not improve from 7.71274\n","Epoch 9/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 4.2982 - acc: 0.1475 - val_loss: 11.3618 - val_acc: 0.0000e+00\n","\n","Epoch 00009: val_loss did not improve from 7.71274\n","Epoch 10/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 3.6853 - acc: 0.1795 - val_loss: 9.7366 - val_acc: 0.0900\n","\n","Epoch 00010: val_loss did not improve from 7.71274\n","Epoch 11/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 3.4828 - acc: 0.1759 - val_loss: 9.4135 - val_acc: 0.0900\n","\n","Epoch 00011: val_loss did not improve from 7.71274\n","Epoch 12/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 3.1958 - acc: 0.2032 - val_loss: 8.9667 - val_acc: 0.0900\n","\n","Epoch 00012: val_loss did not improve from 7.71274\n","Epoch 13/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 3.0052 - acc: 0.2168 - val_loss: 10.2130 - val_acc: 0.0900\n","\n","Epoch 00013: val_loss did not improve from 7.71274\n","Epoch 14/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.8635 - acc: 0.2222 - val_loss: 10.4436 - val_acc: 0.0142\n","\n","Epoch 00014: val_loss did not improve from 7.71274\n","Epoch 15/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.7685 - acc: 0.2334 - val_loss: 10.8379 - val_acc: 0.0900\n","\n","Epoch 00015: val_loss did not improve from 7.71274\n","Epoch 16/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.8283 - acc: 0.2447 - val_loss: 11.2199 - val_acc: 0.0213\n","\n","Epoch 00016: val_loss did not improve from 7.71274\n","Epoch 17/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.6339 - acc: 0.2530 - val_loss: 11.2733 - val_acc: 0.0213\n","\n","Epoch 00017: val_loss did not improve from 7.71274\n","Epoch 18/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.5405 - acc: 0.2879 - val_loss: 10.4519 - val_acc: 0.0284\n","\n","Epoch 00018: val_loss did not improve from 7.71274\n","Epoch 19/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.4594 - acc: 0.3110 - val_loss: 11.2997 - val_acc: 0.0900\n","\n","Epoch 00019: val_loss did not improve from 7.71274\n","Epoch 20/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.3621 - acc: 0.3412 - val_loss: 10.6184 - val_acc: 0.0284\n","\n","Epoch 00020: val_loss did not improve from 7.71274\n","Epoch 21/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.2665 - acc: 0.3507 - val_loss: 10.4178 - val_acc: 0.0284\n","\n","Epoch 00021: val_loss did not improve from 7.71274\n","Epoch 22/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 2.0988 - acc: 0.3969 - val_loss: 10.7231 - val_acc: 0.0047\n","\n","Epoch 00022: val_loss did not improve from 7.71274\n","Epoch 23/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 1.9207 - acc: 0.4342 - val_loss: 10.8784 - val_acc: 0.0284\n","\n","Epoch 00023: val_loss did not improve from 7.71274\n","Epoch 24/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 1.7007 - acc: 0.4905 - val_loss: 11.6668 - val_acc: 0.0355\n","\n","Epoch 00024: val_loss did not improve from 7.71274\n","Epoch 25/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 1.4684 - acc: 0.5770 - val_loss: 11.6005 - val_acc: 0.0047\n","\n","Epoch 00025: val_loss did not improve from 7.71274\n","Epoch 26/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 1.2202 - acc: 0.6487 - val_loss: 10.8078 - val_acc: 0.0071\n","\n","Epoch 00026: val_loss did not improve from 7.71274\n","Epoch 27/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 1.0383 - acc: 0.7026 - val_loss: 10.8293 - val_acc: 0.0142\n","\n","Epoch 00027: val_loss did not improve from 7.71274\n","Epoch 28/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.8393 - acc: 0.7607 - val_loss: 11.5558 - val_acc: 0.0142\n","\n","Epoch 00028: val_loss did not improve from 7.71274\n","Epoch 29/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.6806 - acc: 0.7980 - val_loss: 11.6687 - val_acc: 0.0142\n","\n","Epoch 00029: val_loss did not improve from 7.71274\n","Epoch 30/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.5368 - acc: 0.8460 - val_loss: 12.1362 - val_acc: 0.0142\n","\n","Epoch 00030: val_loss did not improve from 7.71274\n","Epoch 31/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.4013 - acc: 0.8963 - val_loss: 11.9889 - val_acc: 0.0024\n","\n","Epoch 00031: val_loss did not improve from 7.71274\n","Epoch 32/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.3624 - acc: 0.8999 - val_loss: 11.1552 - val_acc: 0.0142\n","\n","Epoch 00032: val_loss did not improve from 7.71274\n","Epoch 33/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.3240 - acc: 0.9082 - val_loss: 11.1564 - val_acc: 0.0142\n","\n","Epoch 00033: val_loss did not improve from 7.71274\n","Epoch 34/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.2833 - acc: 0.9230 - val_loss: 11.0151 - val_acc: 0.0142\n","\n","Epoch 00034: val_loss did not improve from 7.71274\n","Epoch 35/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.2753 - acc: 0.9212 - val_loss: 10.6299 - val_acc: 0.0142\n","\n","Epoch 00035: val_loss did not improve from 7.71274\n","Epoch 36/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1989 - acc: 0.9425 - val_loss: 9.7200 - val_acc: 0.0047\n","\n","Epoch 00036: val_loss did not improve from 7.71274\n","Epoch 37/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1969 - acc: 0.9461 - val_loss: 10.5067 - val_acc: 0.0047\n","\n","Epoch 00037: val_loss did not improve from 7.71274\n","Epoch 38/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1791 - acc: 0.9455 - val_loss: 10.1343 - val_acc: 0.0047\n","\n","Epoch 00038: val_loss did not improve from 7.71274\n","Epoch 39/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1873 - acc: 0.9479 - val_loss: 10.0627 - val_acc: 0.0047\n","\n","Epoch 00039: val_loss did not improve from 7.71274\n","Epoch 40/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1491 - acc: 0.9550 - val_loss: 10.3206 - val_acc: 0.0047\n","\n","Epoch 00040: val_loss did not improve from 7.71274\n","Epoch 41/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1295 - acc: 0.9650 - val_loss: 9.8417 - val_acc: 0.0047\n","\n","Epoch 00041: val_loss did not improve from 7.71274\n","Epoch 42/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1597 - acc: 0.9585 - val_loss: 9.1796 - val_acc: 0.0355\n","\n","Epoch 00042: val_loss did not improve from 7.71274\n","Epoch 43/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1301 - acc: 0.9656 - val_loss: 8.8968 - val_acc: 0.0047\n","\n","Epoch 00043: val_loss did not improve from 7.71274\n","Epoch 44/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.2051 - acc: 0.9502 - val_loss: 9.3425 - val_acc: 0.0071\n","\n","Epoch 00044: val_loss did not improve from 7.71274\n","Epoch 45/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1493 - acc: 0.9556 - val_loss: 9.0736 - val_acc: 0.0332\n","\n","Epoch 00045: val_loss did not improve from 7.71274\n","Epoch 46/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.0900 - acc: 0.9757 - val_loss: 9.5085 - val_acc: 0.0237\n","\n","Epoch 00046: val_loss did not improve from 7.71274\n","Epoch 47/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1089 - acc: 0.9739 - val_loss: 9.3393 - val_acc: 0.0190\n","\n","Epoch 00047: val_loss did not improve from 7.71274\n","Epoch 48/48\n","1688/1688 [==============================] - 2s 1ms/step - loss: 0.1149 - acc: 0.9668 - val_loss: 9.0498 - val_acc: 0.0545\n","\n","Epoch 00048: val_loss did not improve from 7.71274\n"],"name":"stdout"}]}]}